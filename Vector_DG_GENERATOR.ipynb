{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeuZpEBS55D8"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPPHiHKvVbMA"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain sentence-transformers cohere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpyrVBhDwlZk",
        "outputId": "e02c01f5-402e-4a23-aaf5-34fcaf079a17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0.post1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33STsJ-a00gU",
        "outputId": "30d40003-9957-48c2-8273-6ee658abd5a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank_bm25) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install rank_bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1awQB98Vjf9",
        "outputId": "03e5d4e2-0a5e-47ff-cce1-119d9a8841b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLl36ulNxIEn",
        "outputId": "2ee1670b-d13c-4dd5-9284-d2fbf37d2733"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.2.6)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.6 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.6)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.11)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.83)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.6->langchain-community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.6->langchain-community) (2.8.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain-community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain-community) (2.20.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JxriG3IV21f"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import CohereRerank\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pC7XoJpYjQE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# HF_token = getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SPLFzjtYlXe"
      },
      "outputs": [],
      "source": [
        "# os.environ['HUGGINGFACEHUB_API_TOKEN'] = HF_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cr80z3gVYsAw"
      },
      "outputs": [],
      "source": [
        "dataset_folder_path='/content/drive/MyDrive/RESUMES/resume_dataset (1)'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYe1eQPTx4td",
        "outputId": "ca57e8ac-faa5-45a9-e402-5bcd23c1f58e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.2.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAs40WoqY4Vk",
        "outputId": "4ee1670e-958f-4002-d816-79054faa956b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 12 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 15 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 18 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 22 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 24 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 26 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 33 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 35 0 (offset 0)\n",
            "WARNING:pypdf._reader:incorrect startxref pointer(3)\n",
            "WARNING:pypdf._reader:incorrect startxref pointer(3)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 7 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 9 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 11 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 13 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 12 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 14 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 16 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 18 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 22 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 24 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 26 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 29 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 35 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 42 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 12 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 14 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 16 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 18 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 22 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 24 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 26 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 28 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 31 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 33 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 13 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 15 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 22 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 24 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 28 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 30 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 32 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 38 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 40 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 42 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 44 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 46 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 48 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 51 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 11 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 12 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 16 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 19 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 21 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 23 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 25 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 12 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 15 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 17 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 19 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 21 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 27 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 29 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 31 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 33 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 35 0 (offset 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping empty file: sandhyalakshmi676@gmail.com_resume.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 15 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 17 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 19 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 21 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 23 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 26 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 28 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 30 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 32 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 34 0 (offset 0)\n",
            "WARNING:pypdf._reader:incorrect startxref pointer(3)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 7 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 9 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 11 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 13 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 23 0 (offset 0)\n",
            "WARNING:pypdf._reader:incorrect startxref pointer(3)\n",
            "WARNING:pypdf._reader:incorrect startxref pointer(3)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 11 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 13 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 12 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 14 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 16 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 18 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 23 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 26 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 28 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 14 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 21 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 32 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 39 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 12 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 14 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 17 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 19 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 21 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 23 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 14 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 16 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 18 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 22 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 24 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 26 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 28 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 30 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 32 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 34 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 36 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 38 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 40 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 42 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 44 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 46 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 9 0 (offset 0)\n",
            "WARNING:pypdf._reader:invalid pdf header: b'-----'\n",
            "WARNING:pypdf._reader:incorrect startxref pointer(1)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 7 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 9 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 11 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 13 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 15 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 17 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 19 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 28 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 35 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 65 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 76 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 12 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 14 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 16 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 18 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 22 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 25 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 27 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 33 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 35 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 37 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 42 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 49 0 (offset 0)\n",
            "WARNING:pypdf._reader:invalid pdf header: b'-----'\n",
            "WARNING:pypdf._reader:incorrect startxref pointer(3)\n",
            "WARNING:pypdf._reader:incorrect startxref pointer(3)\n",
            "WARNING:pypdf._reader:incorrect startxref pointer(3)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 15 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 17 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 23 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 36 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 12 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 15 0 (offset 0)\n",
            "WARNING:pypdf._reader:incorrect startxref pointer(3)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 12 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 14 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 16 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 18 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 22 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 24 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 26 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 28 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 30 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 32 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 34 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 36 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 38 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 40 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 47 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 49 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 51 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 13 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 15 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 21 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 23 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 25 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 27 0 (offset 0)\n",
            "WARNING:pypdf._reader:incorrect startxref pointer(3)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:incorrect startxref pointer(3)\n"
          ]
        }
      ],
      "source": [
        "# documents=[]\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "# file_count = 0\n",
        "# max_files = 100\n",
        "# # from PyPDF2 import PdfFileReader,PdfReader\n",
        "# for file in os.listdir(dataset_folder_path):\n",
        "#     # if file_count >= max_files:\n",
        "#     #     break\n",
        "#     file_path = os.path.join(dataset_folder_path, file)\n",
        "#     loader = PyPDFLoader(file_path)\n",
        "#     documents.extend(loader.load())\n",
        "#     # file_count += 1\n",
        "\n",
        "\n",
        "documents = []\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "import os\n",
        "\n",
        "# dataset_folder_path = '/path/to/your/dataset/folder'\n",
        "max_files = 100\n",
        "file_count = 0\n",
        "\n",
        "for file in os.listdir(dataset_folder_path):\n",
        "    file_path = os.path.join(dataset_folder_path, file)\n",
        "\n",
        "    # Check if the file is not empty\n",
        "    if os.path.getsize(file_path) == 0:\n",
        "        print(f\"Skipping empty file: {file}\")\n",
        "        continue\n",
        "\n",
        "    loader = PyPDFLoader(file_path)\n",
        "    try:\n",
        "        loader = PyPDFLoader(file_path)\n",
        "        documents.extend(loader.load())\n",
        "\n",
        "    except :\n",
        "        print(f\"Error loading file {file}\")\n",
        "        continue\n",
        "\n",
        "    # file_count += 1\n",
        "    # if file_count >= max_files:\n",
        "    #     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsf1mWPHyO5-",
        "outputId": "fe565a2d-e7a2-4f74-de7d-f6da21f79af8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1518"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(documents)\n",
        "# print(documents[156])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzIzrMpWZCvc",
        "outputId": "b8c52d39-f7b8-4880-b29b-f315fda45732"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/aks76625@gmail.com_resume.pdf', 'page': 0}, page_content='Anurag Shukla\\nak s76625@gmail.c om | +91 95110 7 5594\\nCAREER GOALS\\nTopursue ajobopportunity inacompetitive\\nenvironment that willchallenge metopush\\nmyboundaries andexpand myknowledge in\\nthefield ofcomputer science while allowing\\nmetoaddvalue tothedynamics ofthecoun-\\ntry.\\nEDUCATION\\nINSTITUTE OF ENGINEERING AND\\nTECHNOLOGY, DAVV\\nB.E. IN INF ORMA TION TECHNOL OG Y\\nA ug 2019 - Ma y 2023 | Indore, M.P\\nCGP A: 8.32/ 10\\nBETHANY CONVENT SCHOOL\\nINTERMEDIA TE (PCM)\\nMa y 2018 | ALLAHAB AD, U .P\\nPERCENT AGE: 92.4\\nDELHI PUBLIC SCHOOL\\nHIGH SCHOOL\\nMa y 2016 | V ADOD AR A , GU J AR A T\\nCGP A: 10 / 10\\nLINKS\\nPortfolio: Anurag Shukla\\nGithub: aks1817\\nLinkedIn: Anurag Shukla\\nInterviewBit: Anurag Shukla\\nLeetCode: aks76625\\nGeeksforGeeks: aks76625\\nHackerRank: Anurag_1817\\nCOURSEWORK\\nUNDERGRADUATE\\nDatabase Management Systems\\nOperating Systems\\nComputer Organisation &Architecture\\nComputer Networks\\nData Structure andAlgorithms\\nObject Oriented Programming\\nSoftware Engineering\\nSKILLS\\nLANGUAGES\\n•C/C++ •Java •Javascript •HTML •CSS\\nFRAMEWORKS\\n•ReactJS •React-Native •Redux •\\nBootstrap •Express.js\\nDATABASES\\n•MySQL •MongoDBEXPERIENCE\\nWYSE | Software Development Engineer - 1\\nJ un 2023 – Dec 2023 | Bengaluru, KA\\n•Involved intheentire mobile appdevelopment lifecycle\\n•Emphasis oncreating aseamless user experience\\n•Designed andimplemented navigation systems\\n•Implemented notification features\\n•Developed direct messaging functionality\\n•Contributed topost creation features\\n•Played acrucial roleinoptimizing appperformance\\n•Developed APIs using theDjango framework\\nWYSE | Full Stack Developer Intern\\nFeb 2023 – Ma y 2023 | Remo te\\n•Designed keyscreens\\n•Implemented Firebase mobile authentication\\n•Established Redux Toolkit forstate management\\n•Integrated APIforseamless functionality\\nANAROCK TECHNOLOGY | Software E ngineering Intern\\nJ une 2022 – Oct ober 2022 | Remo te\\n•Wrote APIs forthenewrental feature\\n•Integrated Airtable forenhanced functionality\\n•Played akeyroleinenhancing theemail management system\\nANAROCK TECHNOLOGY | Software E ngineering Intern\\nSep 2021 – No v 2021 | Remo te\\n•Specialized inUI/UX enhancements\\n•Contributed todesigning screens forAnarocks Sales App\\n•Proficient indebugging\\n•Ensured optimal functionality oftheapplication\\nPROJECTS\\nAMAZON CLONE | GITHUB LINK\\nMongoDB | Express.js | ReactJS | Node.js\\nAsmall webappusing MERN Stack thattries toimitate thedesktop web\\nversion ofAmazon ,user canadditems tothebasket, delete them, and\\nhave authentication feature with thehelpofFirebase .\\nUBER EATS CLONE | GITHUB LINK\\nREAC T -NA TIVE | REDUX | FIREB A SE | YELP - API\\nAsmall android appusing React-Native thattries toimitate themobile\\nversion ofUber Eats,youcanadditems tothecart,remove them, and\\ncheckout cartandstore order details with thehelpofFirebase .\\nDEV CONNECTOR | GITHUB LINK\\nMongoDB | Express.js | ReactJS | Node.js\\nDevConnector isafullstack application built ontheMERN stack. Its\\nProcides platform fordevelopers toconnect with other dev’s andeven\\nshare posts.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/sharanlata132@gmail.com_resume.pdf', 'page': 0}, page_content='LATA SHARAN\\n+91 9456044670 ⋄Indra Nagar, Aligarh, UP, India\\nsharanlata132@gmail.com ⋄https://www.linkedin.com/in/lata-sharan-6b283b207/ ⋄https://github.com/Lata-Sharan\\nOBJECTIVE\\nSoftware Engineer with 1+ years of experience in Data Analysis, writing Test Cases for Automotive Functions and\\nHIL Manual and Automation Testing along with writing python scripts for new ECU architecture. Parallel to that,\\nI am pursuing Post Graduate Programme in Data Science and Machine Learning from Intellipat, seeking full-time\\nData Analyst or Data Scientist roles.\\nEDUCATION\\nPGP in Data Science and Machine Learning , Intellipat September 2023 - Present\\nMySQL\\nPython Basics and OOPS Concept\\nInferential Statistics\\nNumpy, Pandas, Machine Learning\\nBSc Hons. (Computer Applications) , Aligarh Muslim University August 2019- July 2022\\nSeminar Paper Presentation: CNN (Convolutional Neural Networks)\\nMajor Project: Drowsiness Detection System\\nMinor Project: Hostel Management Website[Teamwork]\\nSKILLS\\nTECHNICAL SKILLS: MySQL, Python, Data Analysis, Git, Microsoft Office, OpenCV, Vector CANAPE, dSPACE, Tensor-\\nflow, SkLearn, Machine Learning, Numpy, Pandas, Matplotlib, Data Transformation\\nSOFT SKILLS: Innovation, Adaptability, Teamwork, Creativity, Analytical Thinking, Multi Tasking, issue resolution, Planning\\nand Delivery, Fluent Communication\\nEXPERIENCE\\nSoftware Engineer Nov 2022 - Present\\nDiensten Tech Ltd (Client Maruti Suzuki India Ltd) Gurugram, Haryana\\n•Optimization of HILS Automation Script in python according to new Automotive ECU Architecture.\\n•HILS Automation Testcase Preparation for ECGW and EIU\\n•HILS Testing and Analysis(dSPACE Control/Automation Desk and Vector CANOE/CANAPE)\\n•Testing of Body Control Module Functions prepared by Suppliers\\n•Data Analysis on Time Series Data\\nMachine Learning Intern 1 June 2021 - 31 July 2021\\nGoogle Developer Students Club, AMU AMU, India\\n•Deployed Used-Car-Price Prediction Model on Heroku App using FastAPI and ML algorithms.\\n•Algorithm Used: Linear Regression, SVR(Support Vector Regression), KNN(K-Nearest Neighbour), Decision\\nTree, Random Forest.\\nPROJECTS\\nDrowsiness Detection System This system was trained over 84000 images. It raise an alarm if drowsiness is\\ndetected.Different modules and python libraries were used for Data Preparation. Then model was trained on Transfer\\nLearning Approach using Inception V3 and ResNet-50 CNN architectures. Later, the trained model was validated\\nusing Haarcascade Classifier, and OpenCV (Github Link)'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/sharanlata132@gmail.com_resume.pdf', 'page': 1}, page_content='Unsupervised Machine Learning Projects Worked on 2 projects related to Unsupervised Learning: Credit card\\nClustering and College Reports data. In these projects, I preprocessed data using Standard Scaler and PCA. Then,\\nused K Means, Agglomerative, DBSCAN clustering to get the highest Silhouette value and better accuracy(Github\\nLink)\\nSupervised Machine Learning Projects Worked on 2 projects related to Supervised Learning: Insurance(Linear\\nRegression) and Soccer Fever(Logistic Regression). In these projects algorithms used are Linear Regression, Ridge,\\nLasso, AdaBoost, SVM, KNeighbor Classifier, Decision Tree, Random Forest to get better accuracy(Github Link)\\nHONOURS AND CERTIFICATES\\n•HACKER RANK PROBLEM SOLVING\\nSilver badge(4 Star) https://www.hackerrank.com/sharanlata132\\n•LEETCODE SQL 50 Badge\\nhttps://leetcode.com/Sharanlata/\\n•SDS BIT Mesra ML Contest\\n21st rank in 126 on Public Leaderboard\\n•MISS TALENTED 2017\\nCertificate Of Honour\\n•ENGLISH ACCESS MICROSCHOLARSHIP PROGRAM (2014-2015)sponsored by US Embassy\\nCertificate Of Completion\\nLEADERSHIP\\n•Kabaddi captain (2018-2019)\\n•Secretary Hindi Society (2016-2017)')]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvI6o9HRZEyG",
        "outputId": "66cb4cdd-8d4c-4e41-deaa-0e7a2a040e4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1518"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZlMu4FL6Ets"
      },
      "source": [
        "### Chunking the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGT04s6zZRcE",
        "outputId": "bd192dc6-1b7d-4024-b9ea-d5b887a315d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9341\n"
          ]
        }
      ],
      "source": [
        "text_splitter=RecursiveCharacterTextSplitter(chunk_size=512,chunk_overlap=50)\n",
        "text_splits=text_splitter.split_documents(documents)\n",
        "print(len(text_splits))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg2wh1dD6Iez"
      },
      "source": [
        "### Embedding Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5AJEEpEZbB6",
        "outputId": "86d645b5-a03a-4cf7-efa6-f297373c24ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "embeddings = HuggingFaceBgeEmbeddings(\n",
        "    model_name=\"BAAI/bge-small-en-v1.5\",  # alternatively use \"sentence-transformers/all-MiniLM-l6-v2\" for a light and faster experience.\n",
        "    # model_kwargs={'device':'cpu'},\n",
        "    # encode_kwargs={'normalize_embeddings': True}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Taq_vvxUZm6W"
      },
      "outputs": [],
      "source": [
        "vectorstore = FAISS.from_documents(text_splits, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1XSYzBoVPnn"
      },
      "outputs": [],
      "source": [
        "vectorstore.save_local(\"embedding1000\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7pLyG2H6VAp"
      },
      "source": [
        "## **Implementing Hybrid Search with ensemble Retrieval**\n",
        "\n",
        "> Indented block\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4CZMZzwZpty"
      },
      "outputs": [],
      "source": [
        "retriever_vectordb = vectorstore.as_retriever(search_kwargs={\"k\": 20})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIaE1Ndi0VaR"
      },
      "outputs": [],
      "source": [
        "keyword_retriever = BM25Retriever.from_documents(text_splits)\n",
        "keyword_retriever.k =  10\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxW1DOf70b3Q"
      },
      "outputs": [],
      "source": [
        "ensemble_retriever = EnsembleRetriever(retrievers=[retriever_vectordb,keyword_retriever],\n",
        "                                       weights=[0.5, 0.5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7yn-nAScMoE"
      },
      "outputs": [],
      "source": [
        "query=\"machine learning engineer with 5 year experience\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaHWspUfjvuQ"
      },
      "outputs": [],
      "source": [
        "docs_and_scores = retriever_vectordb.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM1NnzYbj8Qj",
        "outputId": "204a5c57-da94-40ca-c15e-6504c3fcacb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/bhatiatushar02@gmail.com_resume.pdf', 'page': 0}, page_content='learning techniques and algorithms for accurate identification and assessment.\\n◦Tech Stack : Python, Tensorflow, OpenCV'), Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/utpalraj040503@gmail.com_resume.pdf', 'page': 0}, page_content='Natural Language Processing in TensorFlow  by DeepLearning.AI | StatPhysics  India Conference and Summer School | AI Intern at Cloud Counselling  \\n Machine  Learning  Specialization  by Stanford  University  and DeepLearning.AI  | Supervised  Machine  Learning:  Regression  and Classification  | Advanced  Learning \\nAlgorithms  | Unsupervised Learning : Recommenders, Reinforcement  Learning  | Data Science Intern at YBI Foundation'), Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/chanderaravi1005@gmail.com_resume.pdf', 'page': 0}, page_content='Skills/Relevant coursework\\n•Skills:Python | Tensorflow(keras) | PyTorch | Azure | Docker | Kafka | PySpark | GIT | MongoDB | Flask |\\nLangchain\\n•Courses: Artificial Intelligence | Machine learning | Deep learning | Natural Language Processing | Big data |\\nCloud computing and Edge ML | statistics and probability | Optimization and linear algebra'), Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/chethandanivas@gmail.com_resume.pdf', 'page': 8}, page_content='Optimization, Convex Optimization\\xa0\\n\\xa0\\nMachine Learning:\\xa0\\n\\xa0\\nTechniques: Classification, Regression, Clustering, Dimensionality Reduction, Text Analytics, Deep\\nLearning, Time Series Modeling, Optimization, Computer Vision, NLP, LLMs, Deep Learning, RNN, LSTM,\\nCNN\\xa0\\nDomains: CRM, Financial Services, Telecom, Biometrics, Retail, BFSI\\xa0\\n\\xa0\\nTools/Libraries: Matlab, libsvm, Scikit-Learn, Tensorflow, Keras, PyTorch\\xa0\\nStanford NLP, NLTK, Google BERT, OpenCV, GPT3, LLaMA2, LangChain\\xa0\\nVisualization: Tableau, Matplotlib'), Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/1704346541089_resume.pdf', 'page': 1}, page_content='•Convolutional Neural Networks in TensorFlow Link\\n•Natural Language Processing in TensorFlow Link\\n•Sequences, Time Series and Prediction Link\\n•Supervised Machine Learning: Regression and Classification Link\\n•Advanced Learning Algorithms Link\\n•Unsupervised Learning, Recommenders, Reinforcement Learning Link\\n•TensorFlow Developer Specialization Link\\n•Machine Learning Specialization Link\\n•Google Kickstart 2022 Link\\nACHIEVEMENTS\\n•Achieved Global Rank 1469 in Google KickStart.'), Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/vmoksh.shah179@gmail.com_resume.pdf', 'page': 3}, page_content='8Z8FKT3K7WVW\\nData Engineering, Big Data, and Machine Learning on GCP Specialization  -\\nCoursera\\nUY2U2KK2VS8K\\nVimox Shah - page 4'), Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/maddagat@asu.edu_resume.pdf', 'page': 0}, page_content='into equal parts using  OpenCV , and classify the identified digits implementing  CNN Classification  using the TensorFlow  \\nframework , which trains the deep -learning framework  using the MNIST dataset .  \\n \\n EDUCATION      \\n \\nMaster of Science , Computer Engineering (Computer Systems)                                                                                           Jan 2022 - Dec 2023'), Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/utpalraj040503@gmail.com_resume.pdf', 'page': 0}, page_content='Skills: Data Science and Analysis  | Machine Learning  | Deep Learning  | MLOps | Natural Language Processing |Generative AI  | Data Structure and Algorithms  \\n Libraries and frameworks: NumPy | Pandas | Matplotlib | Seaborn | LangChain |Flask |  FastAPI | Scikit -Learn | TensorFlow | Hugging face  | Django  \\n Tools: Jupyter Notebook | Visual Studio Code | Microsoft  Office  | Linux |  Git | Agile  | Docker  |WanDB  | Tableau | PowerBI  | DVC | MLflow | Airflow'), Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/gbr8214@gmail.com_resume.pdf', 'page': 0}, page_content=\"optimize large-scale ML models. Developed Deep learning-based solutions for object detection and classification \\nusing deep learning frameworks like Keras and TensorFlow and scalable ML models deployed as API's\\nEXPERIENCE\\n AI/ML Engineer\\n RecoSense Infosolutions January 2022 - November 2023Bengaluru, India ,\\nExpertise in creating Robust Solutions to solve challenging problems in the domain of NLP, and computer vision \\nand serve them as microservices. •\"), Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/nikhilbagul37@gmail.com_resume.pdf', 'page': 0}, page_content='● Built a Machine Learning Classification model  having an accuracy of 89.94% through  Logistic  Regression, 86% through  Random \\nForest Classifier.  \\n● Implemented TensorFlow and Keras to build  a deep learning model  achieving 91%  and 43% F1 Score for classes  0 and 1 \\nrespectively . \\n● Applied  OneHotEncoder  to perform Feature Encoding  and MInMaxScaler  to perform Feature scaling. \\n● Aggregated and visualized the data by using pandas, matplotlib , and Seaborn  to compile a professional report .')]\n"
          ]
        }
      ],
      "source": [
        "print(docs_and_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTedDTz0cQle",
        "outputId": "274d2fa0-55a4-4a2d-b0d9-e7f26fdcf64e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/bhatiatushar02@gmail.com_resume.pdf', 'page': 0}, page_content='learning techniques and algorithms for accurate identification and assessment.\\n◦Tech Stack : Python, Tensorflow, OpenCV'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/gbr8214@gmail.com_resume.pdf', 'page': 0}, page_content='Implemented and evaluated artificial intelligence and machine learning algorithms and neural networks for diverse \\nindustries. •\\nPrototyped machine learning applications and quickly determined application viability. •\\nCreated customized applications to be used for critical predictions, automated reasoning and decisions, and \\ncalculated optimization algorithms. •\\nResearched, designed, and implemented machine learning applications to solve business problems affecting many \\nusers.•\\nPROJECTS'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/utpalraj040503@gmail.com_resume.pdf', 'page': 0}, page_content='Natural Language Processing in TensorFlow  by DeepLearning.AI | StatPhysics  India Conference and Summer School | AI Intern at Cloud Counselling  \\n Machine  Learning  Specialization  by Stanford  University  and DeepLearning.AI  | Supervised  Machine  Learning:  Regression  and Classification  | Advanced  Learning \\nAlgorithms  | Unsupervised Learning : Recommenders, Reinforcement  Learning  | Data Science Intern at YBI Foundation'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/bhadani.neeraj.08@gmail.com_resume.pdf', 'page': 0}, page_content='the deployment with machine learning engineers with team spread across the globe. • Set and established best practices for the team to follow in the machine learning space, ensuring high-quality and efficient development processes.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/chanderaravi1005@gmail.com_resume.pdf', 'page': 0}, page_content='Skills/Relevant coursework\\n•Skills:Python | Tensorflow(keras) | PyTorch | Azure | Docker | Kafka | PySpark | GIT | MongoDB | Flask |\\nLangchain\\n•Courses: Artificial Intelligence | Machine learning | Deep learning | Natural Language Processing | Big data |\\nCloud computing and Edge ML | statistics and probability | Optimization and linear algebra'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/rexonpambujya2001@gmail.com_resume.pdf', 'page': 0}, page_content='geo-coordinates, and clustered locations.\\n•Demonstrated the potential of machine learning algorithms to cluster geographic coordinates, leading to significant\\nreductions in transportation costs and improved delivery times.\\nProjects\\nDiabetes Prediction and Classification |GitHub Jul 2022 –Dec 2022\\n•Developed an adept machine learning web application utilizing StreamLit, accurately predicting diabetes onset\\nbased on diagnostic data.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/chethandanivas@gmail.com_resume.pdf', 'page': 8}, page_content='Optimization, Convex Optimization\\xa0\\n\\xa0\\nMachine Learning:\\xa0\\n\\xa0\\nTechniques: Classification, Regression, Clustering, Dimensionality Reduction, Text Analytics, Deep\\nLearning, Time Series Modeling, Optimization, Computer Vision, NLP, LLMs, Deep Learning, RNN, LSTM,\\nCNN\\xa0\\nDomains: CRM, Financial Services, Telecom, Biometrics, Retail, BFSI\\xa0\\n\\xa0\\nTools/Libraries: Matlab, libsvm, Scikit-Learn, Tensorflow, Keras, PyTorch\\xa0\\nStanford NLP, NLTK, Google BERT, OpenCV, GPT3, LLaMA2, LangChain\\xa0\\nVisualization: Tableau, Matplotlib'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/sureshbhojwanics@gmail.com_resume.pdf', 'page': 0}, page_content='develop Optimized Machine \\nlearning Systems. \\nLeading a small team of 50 on various data science \\nprojects and\\nworked Automation of tasks using Python \\nand created end to end\\npipelines from scratch from \\nalgorithm design to deployment into\\nproduction\\n.\\n \\nSoftware Consultant ML/AI \\nIndipendent consultant \\n2016 - 2018\\n, \\n \\nRemote \\nWorked as machine learning engineer on classical machine learning,\\nNLP , Deep learning projects ,Deployment and integration with UI ,'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/1704346541089_resume.pdf', 'page': 1}, page_content='•Convolutional Neural Networks in TensorFlow Link\\n•Natural Language Processing in TensorFlow Link\\n•Sequences, Time Series and Prediction Link\\n•Supervised Machine Learning: Regression and Classification Link\\n•Advanced Learning Algorithms Link\\n•Unsupervised Learning, Recommenders, Reinforcement Learning Link\\n•TensorFlow Developer Specialization Link\\n•Machine Learning Specialization Link\\n•Google Kickstart 2022 Link\\nACHIEVEMENTS\\n•Achieved Global Rank 1469 in Google KickStart.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/shridharbenni7@gmail.com_resume.pdf', 'page': 0}, page_content='Chip (SoC) solutions,  specifically  focusing  on the VS640 and VS680 platforms.  \\n• Primary  responsibility  was to implement  machine  learning  models  on the VS640  and VS680  platforms,  focusing  on the \\ndeployment of an Image Segmentation model for background replacement during video calls . \\n• Integrated advanced machine learning models and utilized quantization techniques for optimization. Employed'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/vmoksh.shah179@gmail.com_resume.pdf', 'page': 3}, page_content='8Z8FKT3K7WVW\\nData Engineering, Big Data, and Machine Learning on GCP Specialization  -\\nCoursera\\nUY2U2KK2VS8K\\nVimox Shah - page 4'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/shrutigupta90283@gmail.com_resume.pdf', 'page': 0}, page_content='Professional Experience\\nEducation\\nAccomplishments\\nCertificationsDriven Data Science Intern ready to thrive in demanding digital\\nintelligence processing environments. Well-informed on latest\\nmachine learning advancements. Ready to combine tireless hunger\\nfor new skills with desire to exploit cutting-edge data science\\ntechnology.\\nData Science Intern\\nConsultIT Company ,Greater Noida\\nTranslated cost and benefits of machine learning\\ntechnology for non-technical audiences.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/maddagat@asu.edu_resume.pdf', 'page': 0}, page_content='into equal parts using  OpenCV , and classify the identified digits implementing  CNN Classification  using the TensorFlow  \\nframework , which trains the deep -learning framework  using the MNIST dataset .  \\n \\n EDUCATION      \\n \\nMaster of Science , Computer Engineering (Computer Systems)                                                                                           Jan 2022 - Dec 2023'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/abhishekkale320@gmail.com_resume.pdf', 'page': 0}, page_content='- Analyzed extensive datasets to extract actionable insights, utilizing advanced statistical techniques and machine\\nlearning models.\\n- Developed predictive models that significantly enhanced decision-making processes within the organization.\\n- Collaborated closely with cross-functional teams to implement data-driven solutions and ensure alignment with\\nstrategic objectives.\\n- Led comprehensive data preprocessing, rigorous statistical analysis, robust machine learning modeling, and effective'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/utpalraj040503@gmail.com_resume.pdf', 'page': 0}, page_content='Skills: Data Science and Analysis  | Machine Learning  | Deep Learning  | MLOps | Natural Language Processing |Generative AI  | Data Structure and Algorithms  \\n Libraries and frameworks: NumPy | Pandas | Matplotlib | Seaborn | LangChain |Flask |  FastAPI | Scikit -Learn | TensorFlow | Hugging face  | Django  \\n Tools: Jupyter Notebook | Visual Studio Code | Microsoft  Office  | Linux |  Git | Agile  | Docker  |WanDB  | Tableau | PowerBI  | DVC | MLflow | Airflow'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/meelusumit45@gmail.com_resume.pdf', 'page': 0}, page_content='Percentage : 97\\nPROJECTS\\nIPL Win Prediction\\nDeveloped a web application using Python, integrating key machine learning libraries such as StreamLit, Pickle,\\nNumPy and Pandas. Implemented a robust machine learning pipeline for efficient data processing and deployed a\\nmodel using classification techniques to predict the winning probability of teams in the 2nd innings of a match.\\nTravel Application **'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/gbr8214@gmail.com_resume.pdf', 'page': 0}, page_content=\"optimize large-scale ML models. Developed Deep learning-based solutions for object detection and classification \\nusing deep learning frameworks like Keras and TensorFlow and scalable ML models deployed as API's\\nEXPERIENCE\\n AI/ML Engineer\\n RecoSense Infosolutions January 2022 - November 2023Bengaluru, India ,\\nExpertise in creating Robust Solutions to solve challenging problems in the domain of NLP, and computer vision \\nand serve them as microservices. •\"),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/harimanu9693@gmail.com_resume.pdf', 'page': 0}, page_content='•Orchestrated and monitored end-to-end machine learning pipelines using MLOP’s.\\n•Implemented Azure ML pipelines to automate the end-to-end machine learning workflow, accelerating data\\npreparation, model training, and online deployment, thus reducing development time by 50%.\\n•Created interactive user interfaces using the Streamlit framework to simplify complex data visualizations for\\nnon-technical audiences, resulting in 20% more informed strategic business decisions.\\nEDUCATION'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/nikhilbagul37@gmail.com_resume.pdf', 'page': 0}, page_content='● Built a Machine Learning Classification model  having an accuracy of 89.94% through  Logistic  Regression, 86% through  Random \\nForest Classifier.  \\n● Implemented TensorFlow and Keras to build  a deep learning model  achieving 91%  and 43% F1 Score for classes  0 and 1 \\nrespectively . \\n● Applied  OneHotEncoder  to perform Feature Encoding  and MInMaxScaler  to perform Feature scaling. \\n● Aggregated and visualized the data by using pandas, matplotlib , and Seaborn  to compile a professional report .'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/lci2020014@iiitl.ac.in_resume.pdf', 'page': 0}, page_content='◦Description: Uses advanced machine learning algorithms that analyze images of skin lesions to detect and\\ndiagnose 7 types of skin cancer diseases accurately.\\n◦Contribution: Backend, data cleaning in ML and integration of ML model with project\\n•Machine Learning Algorithms : Sept 2022\\n◦Techstack: Python, Machine Learning\\n◦Description: Implemented a wide range of machine learning algorithms from scratch in Python, including')]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_rel=ensemble_retriever.get_relevant_documents(query)\n",
        "docs_rel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aNbzh9WzpCd",
        "outputId": "fe4e5168-db3a-4d52-d772-c1241ce83327"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/bhatiatushar02@gmail.com_resume.pdf', 'page': 0}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/gbr8214@gmail.com_resume.pdf', 'page': 0}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/utpalraj040503@gmail.com_resume.pdf', 'page': 0}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/bhadani.neeraj.08@gmail.com_resume.pdf', 'page': 0}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/chanderaravi1005@gmail.com_resume.pdf', 'page': 0}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/rexonpambujya2001@gmail.com_resume.pdf', 'page': 0}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/chethandanivas@gmail.com_resume.pdf', 'page': 8}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/sureshbhojwanics@gmail.com_resume.pdf', 'page': 0}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/1704346541089_resume.pdf', 'page': 1}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/shridharbenni7@gmail.com_resume.pdf', 'page': 0}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/vmoksh.shah179@gmail.com_resume.pdf', 'page': 3}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/shrutigupta90283@gmail.com_resume.pdf', 'page': 0}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/maddagat@asu.edu_resume.pdf', 'page': 0}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/abhishekkale320@gmail.com_resume.pdf', 'page': 0}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/utpalraj040503@gmail.com_resume.pdf', 'page': 0}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/meelusumit45@gmail.com_resume.pdf', 'page': 0}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/gbr8214@gmail.com_resume.pdf', 'page': 0}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/harimanu9693@gmail.com_resume.pdf', 'page': 0}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/nikhilbagul37@gmail.com_resume.pdf', 'page': 0}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/lci2020014@iiitl.ac.in_resume.pdf', 'page': 0}\n",
            "['source', 'page']\n"
          ]
        }
      ],
      "source": [
        "for doc in docs_rel:\n",
        "    x = doc.metadata\n",
        "    print(x)\n",
        "unique_docs = list(set(x))\n",
        "print(unique_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DCCIAzB6wcH"
      },
      "source": [
        "### Implementing Re-ranking with Cohere-Rerank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmebX6o7cVw8"
      },
      "outputs": [],
      "source": [
        "# Cohere_API_token = getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNZyWvTXy5-S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"COHERE_API_KEY\"] =\"<API>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fMTkfXAzBAz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3brldWZ03pPP"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet  cohere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BdR9QG34g16",
        "outputId": "77dc4e2d-779b-4555-a8a8-0262e1916d9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-cohere in /usr/local/lib/python3.10/dist-packages (0.1.8)\n",
            "Requirement already satisfied: cohere<6.0,>=5.5.6 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (5.5.8)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (0.2.11)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (1.34.140)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (1.9.4)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.27.0)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.4.0)\n",
            "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.9.0)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.19.1)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.32.0.20240622)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.0->langchain-cohere) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.0->langchain-cohere) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.0->langchain-cohere) (0.1.83)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.0->langchain-cohere) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.0->langchain-cohere) (8.4.2)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.140 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere) (1.34.140)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere) (0.10.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.0->langchain-cohere) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.0->langchain-cohere) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere<6.0,>=5.5.6->langchain-cohere) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere<6.0,>=5.5.6->langchain-cohere) (2.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain-cohere) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain-cohere) (2.0.7)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (0.23.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.140->boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (4.66.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.140->boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-cohere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h4CYoqEzeyB"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "from langchain_community.llms import Cohere\n",
        "compressor = CohereRerank(top_n=10)\n",
        "# top_n=5\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=retriever_vectordb\n",
        ")\n",
        "compressed_docs = compression_retriever.get_relevant_documents(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQrpWgw0UHel",
        "outputId": "801da717-85c9-4fff-a16a-3cd9ba70c02f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ContextualCompressionRetriever(base_compressor=CohereRerank(client=<cohere.client.Client object at 0x7fae295db3d0>, top_n=10, model='rerank-english-v3.0', cohere_api_key=None, user_agent='langchain:partner'), base_retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceBgeEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7fae22ee5e40>, search_kwargs={'k': 10}))"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compression_retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdXSb_Yyzxll",
        "outputId": "faabed65-2765-4cca-a02f-1b402ca0075c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/sachinmr722@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.9856077}, page_content='Sachin M R\\nComputer Vision EngineerImmediate Joiner | Machine Learning Engineer with 3.9 years of experience and \\na proven track record in developing deep learning models and integrating them \\nwith diverse cloud service providers, including AWS. Proficient in optimizing deep \\nlearning models and porting applications for Edge devices, using containerized \\napplications and orchestrating containers through the AWS cloud or Kubernetes.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/v.gurupraveen123@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.9780936}, page_content='OBJECTIVE  \\nSeasoned Machine Learning Engineer with nearly  3 years of extensive experience in developing \\nadvanced algorithms and models for ML and NLP applications . Proven track record in data \\npreprocessing, and model training, ensuring optimal performance and generalizability. Follows Agile \\nmethodology and adept at collaborating with cross -functional teams and managing projects to \\nsuccessfully deliver  ML and NLP solutions. Seeking to leverage expertise in a dynamic environment'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/evaan2001@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.88202196}, page_content='Java,\\nC\\n•\\n2\\nyrs\\n–\\nJavaScript,\\nCUD A,\\nC++,\\nBash,\\nR\\n•\\n1\\nyr\\n–\\nMATLAB ,\\nSQL,\\nMIPS\\n(Assembly) \\n●\\nEnvironments/T ools:\\n4\\nyrs\\n–\\xa0TensorFlo w,\\nLinux,\\nGit,\\nJupyter ,\\nPyTorch,\\nOpenCV ,\\nNumPy\\n•\\n1\\nyr\\n–\\xa0Raspber ry\\nPi,\\nAWS,\\nSnowflake \\n●\\nCertifications:\\nDeep\\nLearning\\nSpecialization\\n(Coursera)\\nSELECTED\\nWORK\\nEXPERIENCE\\nMachine\\nLearning\\nEngineer\\n(LLM)\\nNov\\n2023\\n–\\nPresent\\nHousality\\n–\\nPython,\\nAWS,\\nHuggingface,\\nML\\nPipeline\\nRemote\\n–\\xa0San\\nFrancisco ,\\nCA\\n●\\nLed\\ndevelopment\\nof\\nan\\nLLM-powered\\nchatbot\\nto\\ncompare\\nuser-uploaded\\nhome'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/sachinmr722@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.33731267}, page_content='Joined as Machine learning and Automation Expert\\nMachine learning engineer\\nCapgemini /  02/2020 - 08/2023\\n•Worked on various deep learning based and Computer vision based ap-\\nplications including image classification, object detection.\\n•Built expertise in optimizing the models for different hardware accelera-\\ntors like CPU, GPU, DSP and NPU.\\n•Designed and Implemented various deep learning model training applica-\\ntions.\\n•Implemented optimized workflows for deep learning model training using'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/navnidhi1210@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.075995214}, page_content='PROFESSIONAL EXPERIENCE\\nMachine Learning Intern\\nW3Dev Private Limited\\nDuring my internship here, I worked on:03/2023 – 11/2023\\nNoida, India\\n- Designed and developed analysis system to extract information from large scale \\ndata in Python.\\n- Designed scalable machine learning algorithms and leveraged knowledge of neural \\nnetwork models into projects.\\nSkills: Python libraries, SQL, Deep learning, Flask, Data Mining and warehousing, \\nData Science, Analytical Skills, Back-End Web Development'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/sureshbhojwanics@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.048405956}, page_content='develop Optimized Machine \\nlearning Systems. \\nLeading a small team of 50 on various data science \\nprojects and\\nworked Automation of tasks using Python \\nand created end to end\\npipelines from scratch from \\nalgorithm design to deployment into\\nproduction\\n.\\n \\nSoftware Consultant ML/AI \\nIndipendent consultant \\n2016 - 2018\\n, \\n \\nRemote \\nWorked as machine learning engineer on classical machine learning,\\nNLP , Deep learning projects ,Deployment and integration with UI ,'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/sureshbhojwanics@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.03507868}, page_content='Science, Big Data, and Enterprise Cloud. \\nWorking as Lead Machine learning engineer on various use cases\\ncollaborated with global Team developers to build and develop\\nOptimized Machine Learning Products and Services \\nLeading a team of 200 on Various Classical and NLP use cases along\\nwith Generative AI and RAG bases use cases leveraging Open AI GPT\\n3/3.5/4 LLM using Prompt engineering \\nVarious data science projects and worked Automation of tasks using\\nPython'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/navnidhi1210@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.018159512}, page_content=\"PROFILE\\nBack End Developer with ML and Python expertise, adept in Agile methodologies. Seeking a role to apply\\nanalytical skills and contribute to impactful projects.\\nEDUCATION\\nB. Tech\\nPunjab Technical University\\nCGPA - 8.0308/2019 – 07/2023\\nMohali, India\\nHigher Secondary\\nBR DAV Public School\\nPercentage - 72.3%07/2017 – 05/2019\\nBegusarai, India\\nSecondary School\\nSt. Paul's School (ICSE Board)\\nPercentage - 88.8%04/2011 – 05/2017\\nBegusarai, India\\nPROFESSIONAL EXPERIENCE\\nMachine Learning Intern\"),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/rahul22051999singh@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.005797401}, page_content='libraries(Scikit-learn, Pandas, Numpy) .\\n{Programming and Deployment : Adept in Python with TensorFlow, Keras, PyTorch ; experienced in cloud\\ndeployment (Azure) andRest API development (FastAPI, Flask) .\\n{MLOps Proficiency : Extensive experience in evaluating and integrating MLOps tools (ClearML, Determined\\nAI, Dataiku) for end-to-end machine learning lifecycle management, including model training, deployment, and\\ninfrastructure optimization.\\nWork Experience\\nSoftware Engineer July 2022 - Present'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/gunashekarchenna8@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.0004305571}, page_content='efficiency  across the regions with autom ated security and malware checks.  \\nINTERNSHIPS  \\n  \\nExperian  | Software Engineer Trainee | MLOps, JupyterHub packag e management           Nov’21 – Jul’22  \\n● Developed a custom -built JupyterLab extension for Feature Engineering and MLOps  using Python and TypeScript . \\nSwiftAI  | Machine Learning and Computer Vision Engineer | CNN, OpenCV, Tensorf low                                  Sep’20 – Mar’21')]"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compressed_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrVR7R9jBIkh",
        "outputId": "b86755c3-dbc4-4631-ba26-f0c65b5e8a86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/sachinmr722@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.9856077}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/v.gurupraveen123@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.9780936}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/evaan2001@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.88202196}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/sachinmr722@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.33731267}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/navnidhi1210@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.075995214}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/sureshbhojwanics@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.048405956}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/sureshbhojwanics@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.03507868}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/navnidhi1210@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.018159512}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/rahul22051999singh@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.005797401}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/gunashekarchenna8@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.0004305571}\n",
            "['source', 'page', 'relevance_score']\n"
          ]
        }
      ],
      "source": [
        "for doc in compressed_docs:\n",
        "    metadata = doc.metadata\n",
        "    print(metadata)\n",
        "unique_docs = list(set(metadata))\n",
        "print(unique_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIgjB5CFlBJI"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "from langchain_community.llms import Cohere\n",
        "compressor = CohereRerank(top_n=10)\n",
        "# top_n=5\n",
        "compression_retriever1 = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=ensemble_retriever\n",
        ")\n",
        "compressed_docs_bm25 = compression_retriever.get_relevant_documents(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek9VWI-TlNKK",
        "outputId": "63ebc13e-e802-4de0-f1ef-b53c93ba25cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ContextualCompressionRetriever(base_compressor=CohereRerank(client=<cohere.client.Client object at 0x7fae295dba90>, top_n=10, model='rerank-english-v3.0', cohere_api_key=None, user_agent='langchain:partner'), base_retriever=EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['FAISS', 'HuggingFaceBgeEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7fae22ee5e40>, search_kwargs={'k': 10}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x7fae22b8fe20>, k=10)], weights=[0.5, 0.5]))"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compression_retriever1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7hOdtwjlPA2",
        "outputId": "f4edda64-a7fd-4e3a-c95c-df9fe0dd7fd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/sachinmr722@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.9856077}, page_content='Sachin M R\\nComputer Vision EngineerImmediate Joiner | Machine Learning Engineer with 3.9 years of experience and \\na proven track record in developing deep learning models and integrating them \\nwith diverse cloud service providers, including AWS. Proficient in optimizing deep \\nlearning models and porting applications for Edge devices, using containerized \\napplications and orchestrating containers through the AWS cloud or Kubernetes.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/v.gurupraveen123@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.9780936}, page_content='OBJECTIVE  \\nSeasoned Machine Learning Engineer with nearly  3 years of extensive experience in developing \\nadvanced algorithms and models for ML and NLP applications . Proven track record in data \\npreprocessing, and model training, ensuring optimal performance and generalizability. Follows Agile \\nmethodology and adept at collaborating with cross -functional teams and managing projects to \\nsuccessfully deliver  ML and NLP solutions. Seeking to leverage expertise in a dynamic environment'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/evaan2001@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.88202196}, page_content='Java,\\nC\\n•\\n2\\nyrs\\n–\\nJavaScript,\\nCUD A,\\nC++,\\nBash,\\nR\\n•\\n1\\nyr\\n–\\nMATLAB ,\\nSQL,\\nMIPS\\n(Assembly) \\n●\\nEnvironments/T ools:\\n4\\nyrs\\n–\\xa0TensorFlo w,\\nLinux,\\nGit,\\nJupyter ,\\nPyTorch,\\nOpenCV ,\\nNumPy\\n•\\n1\\nyr\\n–\\xa0Raspber ry\\nPi,\\nAWS,\\nSnowflake \\n●\\nCertifications:\\nDeep\\nLearning\\nSpecialization\\n(Coursera)\\nSELECTED\\nWORK\\nEXPERIENCE\\nMachine\\nLearning\\nEngineer\\n(LLM)\\nNov\\n2023\\n–\\nPresent\\nHousality\\n–\\nPython,\\nAWS,\\nHuggingface,\\nML\\nPipeline\\nRemote\\n–\\xa0San\\nFrancisco ,\\nCA\\n●\\nLed\\ndevelopment\\nof\\nan\\nLLM-powered\\nchatbot\\nto\\ncompare\\nuser-uploaded\\nhome'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/sachinmr722@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.33731267}, page_content='Joined as Machine learning and Automation Expert\\nMachine learning engineer\\nCapgemini /  02/2020 - 08/2023\\n•Worked on various deep learning based and Computer vision based ap-\\nplications including image classification, object detection.\\n•Built expertise in optimizing the models for different hardware accelera-\\ntors like CPU, GPU, DSP and NPU.\\n•Designed and Implemented various deep learning model training applica-\\ntions.\\n•Implemented optimized workflows for deep learning model training using'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/navnidhi1210@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.075995214}, page_content='PROFESSIONAL EXPERIENCE\\nMachine Learning Intern\\nW3Dev Private Limited\\nDuring my internship here, I worked on:03/2023 – 11/2023\\nNoida, India\\n- Designed and developed analysis system to extract information from large scale \\ndata in Python.\\n- Designed scalable machine learning algorithms and leveraged knowledge of neural \\nnetwork models into projects.\\nSkills: Python libraries, SQL, Deep learning, Flask, Data Mining and warehousing, \\nData Science, Analytical Skills, Back-End Web Development'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/sureshbhojwanics@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.048405956}, page_content='develop Optimized Machine \\nlearning Systems. \\nLeading a small team of 50 on various data science \\nprojects and\\nworked Automation of tasks using Python \\nand created end to end\\npipelines from scratch from \\nalgorithm design to deployment into\\nproduction\\n.\\n \\nSoftware Consultant ML/AI \\nIndipendent consultant \\n2016 - 2018\\n, \\n \\nRemote \\nWorked as machine learning engineer on classical machine learning,\\nNLP , Deep learning projects ,Deployment and integration with UI ,'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/sureshbhojwanics@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.03507868}, page_content='Science, Big Data, and Enterprise Cloud. \\nWorking as Lead Machine learning engineer on various use cases\\ncollaborated with global Team developers to build and develop\\nOptimized Machine Learning Products and Services \\nLeading a team of 200 on Various Classical and NLP use cases along\\nwith Generative AI and RAG bases use cases leveraging Open AI GPT\\n3/3.5/4 LLM using Prompt engineering \\nVarious data science projects and worked Automation of tasks using\\nPython'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/navnidhi1210@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.018159512}, page_content=\"PROFILE\\nBack End Developer with ML and Python expertise, adept in Agile methodologies. Seeking a role to apply\\nanalytical skills and contribute to impactful projects.\\nEDUCATION\\nB. Tech\\nPunjab Technical University\\nCGPA - 8.0308/2019 – 07/2023\\nMohali, India\\nHigher Secondary\\nBR DAV Public School\\nPercentage - 72.3%07/2017 – 05/2019\\nBegusarai, India\\nSecondary School\\nSt. Paul's School (ICSE Board)\\nPercentage - 88.8%04/2011 – 05/2017\\nBegusarai, India\\nPROFESSIONAL EXPERIENCE\\nMachine Learning Intern\"),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/rahul22051999singh@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.005797401}, page_content='libraries(Scikit-learn, Pandas, Numpy) .\\n{Programming and Deployment : Adept in Python with TensorFlow, Keras, PyTorch ; experienced in cloud\\ndeployment (Azure) andRest API development (FastAPI, Flask) .\\n{MLOps Proficiency : Extensive experience in evaluating and integrating MLOps tools (ClearML, Determined\\nAI, Dataiku) for end-to-end machine learning lifecycle management, including model training, deployment, and\\ninfrastructure optimization.\\nWork Experience\\nSoftware Engineer July 2022 - Present'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/gunashekarchenna8@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.0004305571}, page_content='efficiency  across the regions with autom ated security and malware checks.  \\nINTERNSHIPS  \\n  \\nExperian  | Software Engineer Trainee | MLOps, JupyterHub packag e management           Nov’21 – Jul’22  \\n● Developed a custom -built JupyterLab extension for Feature Engineering and MLOps  using Python and TypeScript . \\nSwiftAI  | Machine Learning and Computer Vision Engineer | CNN, OpenCV, Tensorf low                                  Sep’20 – Mar’21')]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compressed_docs_bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKDZKFpulVCw",
        "outputId": "26da0270-d1ad-4bc9-9780-266a20edc990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/sachinmr722@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.9856077}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/v.gurupraveen123@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.9780936}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/evaan2001@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.88202196}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/sachinmr722@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.33731267}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/navnidhi1210@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.075995214}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/sureshbhojwanics@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.048405956}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/sureshbhojwanics@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.03507868}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/navnidhi1210@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.018159512}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/rahul22051999singh@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.005797401}\n",
            "{'source': '/content/drive/MyDrive/RESUMES/resume_dataset (1)/gunashekarchenna8@gmail.com_resume.pdf', 'page': 0, 'relevance_score': 0.0004305571}\n",
            "['source', 'page', 'relevance_score']\n"
          ]
        }
      ],
      "source": [
        "for doc in compressed_docs_bm25:\n",
        "    metadata_bm = doc.metadata\n",
        "    print(metadata_bm)\n",
        "unique_docs_bm = list(set(metadata_bm))\n",
        "print(unique_docs_bm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0r8AkIok4L88"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4YMt_NA4-fe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
